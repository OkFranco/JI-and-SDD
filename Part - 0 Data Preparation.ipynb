{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A - Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The several analyzes developed require the application à priori of several data preparation methods. Fostering greater structure and interpretability of the project, the major methods are here considered, taking into account the different data sources used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "import nltk\n",
    "import nlpnet\n",
    "import swifter\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Traditional media "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section focuses in all the data preparation methods applied only on the traditional media dataset considered (newspaper articles published online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 - Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>Correio da Manhã</td>\n",
       "      <td>É capaz de ser uma brincadeira ritual do Bloco...</td>\n",
       "      <td>Impresso do site do jornal Correio da manhã, e...</td>\n",
       "      <td>http://www.cmjornal.pt/opiniao/detalhe/lingua-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>Presidente diz que o país \"não pode descansar\"</td>\n",
       "      <td>Na mensagem de ano novo, o Presidente da Repúb...</td>\n",
       "      <td>Na mensagem de ano novo, o Presidente da Repúb...</td>\n",
       "      <td>http://www.expresso.pt/africa/presidente-diz-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-07</td>\n",
       "      <td>Mercado accionista continua suportado</td>\n",
       "      <td>Ricardo Valente, presidente da Personal Value ...</td>\n",
       "      <td>Impresso do site do jornal Correio da manhã, e...</td>\n",
       "      <td>http://www.cmjornal.pt/economia/detalhe/mercad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>Falham investimentos portugueses</td>\n",
       "      <td>\"Moçambique não tem petróleo, logo não é tão i...</td>\n",
       "      <td>\"Moçambique não tem petróleo, logo não é tão i...</td>\n",
       "      <td>http://www.expresso.pt/africa/falham-investime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>Nótulas sobre o uso e desuso do guarda-chuva</td>\n",
       "      <td>Roupa para lavar</td>\n",
       "      <td>O Mundo divide-se em duas partes: os fãs do gu...</td>\n",
       "      <td>http://www.expresso.pt/blogues/blog_roupa_para...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                           title  \\\n",
       "0 2007-01-03                                Correio da Manhã   \n",
       "1 2007-01-05  Presidente diz que o país \"não pode descansar\"   \n",
       "2 2007-01-07           Mercado accionista continua suportado   \n",
       "3 2007-01-08                Falham investimentos portugueses   \n",
       "4 2007-01-12    Nótulas sobre o uso e desuso do guarda-chuva   \n",
       "\n",
       "                                                lead  \\\n",
       "0  É capaz de ser uma brincadeira ritual do Bloco...   \n",
       "1  Na mensagem de ano novo, o Presidente da Repúb...   \n",
       "2  Ricardo Valente, presidente da Personal Value ...   \n",
       "3  \"Moçambique não tem petróleo, logo não é tão i...   \n",
       "4                                   Roupa para lavar   \n",
       "\n",
       "                                                body  \\\n",
       "0  Impresso do site do jornal Correio da manhã, e...   \n",
       "1  Na mensagem de ano novo, o Presidente da Repúb...   \n",
       "2  Impresso do site do jornal Correio da manhã, e...   \n",
       "3  \"Moçambique não tem petróleo, logo não é tão i...   \n",
       "4  O Mundo divide-se em duas partes: os fãs do gu...   \n",
       "\n",
       "                                                link  \n",
       "0  http://www.cmjornal.pt/opiniao/detalhe/lingua-...  \n",
       "1  http://www.expresso.pt/africa/presidente-diz-q...  \n",
       "2  http://www.cmjornal.pt/economia/detalhe/mercad...  \n",
       "3  http://www.expresso.pt/africa/falham-investime...  \n",
       "4  http://www.expresso.pt/blogues/blog_roupa_para...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset_media=pd.read_excel(r\"C:\\Users\\franco joao\\OneDrive - The Boston Consulting Group, Inc\\From Egnyte\\Personal\\Programming\\thesis_master\\Data Lilia\\JoaoF_Files\\final_joao_franco_thesis_IJ\\final_joao_franco_thesis_IJ\\SDD_JI_Artigos.xlsx\")\n",
    "\n",
    "original_dataset_media.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 - Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend of each column of the initial dataset used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Unnamed:0|title|lead|body|link|\n",
    "|---|---|---|---|---|\n",
    "|Date of publication of newspaper article|Title of the newspaper article|Resume (lead) of the newspaper articles|Main text (body) of the newspaper article|Web link to access the newspaper article|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15898 entries, 0 to 15897\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Unnamed: 0  15898 non-null  datetime64[ns]\n",
      " 1   title       15898 non-null  object        \n",
      " 2   lead        15880 non-null  object        \n",
      " 3   body        15898 non-null  object        \n",
      " 4   link        15898 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 621.1+ KB\n"
     ]
    }
   ],
   "source": [
    "original_dataset_media.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 - Filling missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_media.lead.fillna(\" \",inplace=True)\n",
    "original_dataset_media.rename(columns={\"Unnamed: 0\":\"Time\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15898 entries, 0 to 15897\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Time    15898 non-null  datetime64[ns]\n",
      " 1   title   15898 non-null  object        \n",
      " 2   lead    15898 non-null  object        \n",
      " 3   body    15898 non-null  object        \n",
      " 4   link    15898 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 621.1+ KB\n"
     ]
    }
   ],
   "source": [
    "original_dataset_media.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 - Converting text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the full string sets in lowercases we can simplified token search\n",
    "for column in original_dataset_media.columns[[1,2,3]]:\n",
    "    original_dataset_media[column]=[*map(str.lower,original_dataset_media[column])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'lead', 'body'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasets of Sustainability (SDD) and Intergenerational Justice (JI)\n",
    "\n",
    "data_media=original_dataset_media.copy()\n",
    "\n",
    "columns=data_media.columns[[1,2,3]]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 - Creating year, trimester and month related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimesters(dataset):\n",
    "\n",
    "    trimester_JI=[]\n",
    "    for month in dataset.month:\n",
    "        if month<=3:\n",
    "            trimester_JI.append(1)\n",
    "        elif month >=10:\n",
    "            trimester_JI.append(4)\n",
    "        elif (month >=4 and month <=6):\n",
    "            trimester_JI.append(2)\n",
    "        else:\n",
    "            trimester_JI.append(3)\n",
    "\n",
    "    dataset[\"trimester\"]=trimester_JI\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media.loc[:,\"year\"]=pd.DatetimeIndex(data_media.Time).year\n",
    "data_media.loc[:,\"month\"]=pd.DatetimeIndex(data_media.Time).month\n",
    "data_media.loc[:,\"trimester\"]=trimesters(data_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 - Removing non-Portuguese observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to ensure that **all the data is from articles published in Portugal**, removing the influence of other portuguese speaking countries (exemple: Brazil). \n",
    "\n",
    "\n",
    "We **considered that if the website is not \".pt\", that it was not published in Portugal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11497    http://publico.uol.com.br/lifestyle/artigo/est...\n",
       "Name: link, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_media[~data_media.link.str.contains(\".pt\")].link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, it is possible to conclude that only 1 observation can be considered as not published in Portugal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media.loc[:,\"PT_data\"]=data_media.link.str.contains(\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 - Identifying JI or SDD related observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the different observations will be **classified as related with sustainability (SDD) or intergenerational justice (JI) , <u>depending on keywords frequency that were selected leveraging internal content knowledge<u>**.\n",
    "  \n",
    "**The presence of the topics in only one component** (body, title or lead) in the article **was considered enough to make the classification**, <u> minimizing false negative errors</u>. It is assumed that these terms are only used in cases strongly linked with the topics being studied, so even one occurrence is a strong indicator of the topic of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected words to classify one observation as related with SDD or as related with JI were selected after an initial ad hoc analysis of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    data_media.loc[:,column + \"SDD\"]=data_media.loc[:,column].str.contains(\"sustentável|insustentável|sustentabilidade|insustentabilidade|sustentar\")\n",
    "    data_media.loc[:,column + \"JI\"]=data_media.loc[:,column].str.contains(\"interger|gerações vindouras|gerações futuras|geração futura|próxima geração|justiça entre gerações|geração vindoura|geração seguinte|gerações presentes|entre gerações|próximas gerações|gerações mais jovens| novas gerações| gerações distintas| próximas gerações\")\n",
    "    \n",
    "data_media[\"SDD\"]=data_media.titleSDD|data_media.leadSDD|data_media.bodySDD\n",
    "data_media[\"JI\"]=data_media.titleJI|data_media.leadJI|data_media.bodyJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 - JI or SDD related topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When approaching SDD or JI, the writer can mention them in the **context of several topics (e.g.: environment, debt, health, among others)**. Therefore, it is important to understand within the observations classified as JI or SDD related, the topics that are related with. This is the focus of the second section.\n",
    "\n",
    "Considering the same rational as for the JI or SDD observation classification method, the number of potential false negatives was considered minimized after a carefull manual consideration. In this case, lower bound assumed to consider one observation as related with debt, for example, was instead 2, considering an initial ad hoc analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate the understanding of the topics that are being analysed, their will translated here:\n",
    "\n",
    "- environment -> ambiente\n",
    "- debt -> dívida\n",
    "- education -> educação\n",
    "- social security -> segurança social\n",
    "- health -> saúde\n",
    "- others -> outros\n",
    "\n",
    "Although it is not a topic being study, there is other theme that is important to know its meaning in portuguese:\n",
    "\n",
    "- politics -> política"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment=[\"ambiente\",\"planeta\",\"terra\",\"água\",\n",
    "          \"floresta\",\"híbrido\",\"incêndio\",\"desfloresta\",\"solo\",\"erosão\",\"reciclar\",\"reutilizar\"]\n",
    "debt=[\"dívida\",\"juros\"]\n",
    "education=[\"educação\",\"escola\",\"estudante\",\"alunos\",\"professores\"]\n",
    "health=[\"saúde\",\"S.N.S\"]\n",
    "\n",
    "social_security=[\"pensão\",\"segurança social\", \"S.S\", \"S.S.\",\"SS\", \"pensões\",\"reformado\",\"reformada\",\n",
    "                  \"pensionistas\",\"contribuinte\",\"discontos\",\"rendimentos\"]\n",
    "\n",
    "\n",
    "\n",
    "others=[\"agricultura\",\"agricultores\",\"agrícola\",\"polícia\",\"TAP\",\"RTP\",\"RDP\"]\n",
    "politics=[\"assembleia da república\",\"governo\",\"ministro\",\"partido\"]\n",
    "\n",
    "topics_name_w_politics=[\"environment\",\"debt\",\"education\",\"health\",\"social_security\",\"others\",\"politics\"]\n",
    "\n",
    "topics_name=[\"environment\",\"debt\",\"education\",\"health\",\"social_security\",\"others\"]\n",
    "\n",
    "topics=[environment,debt,education,health,social_security,others,politics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function values_per_instances was developed to classify each article as related with one of the identified 6 topics, plus politics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key functions that will be used\n",
    "\n",
    "def values_per_instances(instance,lists,lists_name,number):\n",
    "    lists_counter=np.zeros(len(lists_name),dtype=int)\n",
    "    result=[]\n",
    "    for index_list,list_ in enumerate(lists):\n",
    "        for word in list_:\n",
    "            if instance.count(str(word))!=0:\n",
    "                lists_counter[index_list]+=instance.count(str(word))\n",
    "        if lists_counter[index_list]>=number:\n",
    "            result.append(lists_name[index_list])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an article to be classified as environment, health, etc. it is needed to **appear in each article at least two examples of words from that group**, being them unique or not. This reduces the levels of noise in the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8029d0ebd1f475ca15aae8e00857edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/15898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_topics=data_media.body.swifter.apply(lambda x:values_per_instances(x,topics,topics_name_w_politics,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "len(data_topics)==len(data_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the prior output into a dataframe with binary columns the update_database was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_database(content,lists_name):\n",
    "        database=pd.DataFrame(index=np.arange(len(content)),columns=lists_name).fillna(0)\n",
    "        for index_instance,instance in enumerate(content):\n",
    "            for index_item,item in enumerate(instance):\n",
    "                if item in lists_name:\n",
    "                    database.loc[index_instance,item]+=1\n",
    "        return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_topics_count=update_database(data_topics,topics_name_w_politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_info=data_topics_count.politics\n",
    "#we remove the values from the politica column as politics is not considered as a topic\n",
    "data_topics_count[\"total_topics\"]=data_topics_count.sum(axis=1)-data_topics_count.politics\n",
    "data_topics_count[\"year\"]=data_media.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "len(data_topics_count)==len(data_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "(data_topics_count.sum(axis=1)).value_counts().sum()==data_topics.value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data_topics_count DataFrame, we have the necessary information to compile the data_media DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in topics_name_w_politics:\n",
    "    data_media.loc[:,topic]=data_topics_count.loc[:,topic]\n",
    "    \n",
    "data_media.loc[:,\"total_topics\"]=data_media.loc[:,topics_name_w_politics].sum(axis=1)-data_media.politics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 - Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several analyses taken further will require the tokenization of the several newspaper articles, hence the **tokenization techniques required will be applied in this section** to optimize the code.\n",
    "\n",
    "\n",
    "**Several limitations** are recognized, for example nltk is **trained not only from Portuguese from Portugal**, but also in texts from Portuguese from Brazil. Although the sentence construction can be different sometimes, **it is believed that the tokenization process would not be highly impacted**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aac2fe266f4c7ea5d3ad61be288a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/15898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_media.loc[:,\"body_tokens\"]=data_media.body.swifter.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 - Political Party classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function was created to **classify each article as associated with a specific party**. **<u>This association is solely dependent on the number of mentions to a specific party</u>**. With this classification, we intend to know which are the parties that are more mentioned in the articles related to JI or SDD, and the respective topics. The fact that **some articles will be associated with more than 1 party is not a problem**, as there will cases where the same issue is discussed by different parties. In this case, **to reduce some noise, it was considered a minimum number of occurrences of each party name**. 2 occurences as in the topics classfication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the <u>classification process is similar to the one used to classify observations as related to the different topics</u>, **the parties names (E.g.: \"ps\") can be to component of other words (E.g.: psychologist)**. Hence, a new method needed to be used to make the proper classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exact_values_per_instances(instance,lists,lists_name,number):\n",
    "    lists_counter=np.zeros(len(lists_name),dtype=int)\n",
    "    result=[]\n",
    "    for name in lists_name:\n",
    "        counter=0\n",
    "        #although it would be faster to search the tokens from in list with \"lists\", due to the case of PAN, explained below,\n",
    "        #to ensure a complete analysis the search needs to be per token in the instance\n",
    "        for word_index,word in enumerate(instance):\n",
    "            if name!=\"PAN\":\n",
    "                if word in lists[name]:\n",
    "                    counter+=1\n",
    "            else:\n",
    "                #this specific condition was inserted due to the particulary mention to the movie \"peter pan\" \n",
    "                #that does not refer at all to the political party pan\n",
    "                if (word in lists[name]) & (instance[word_index-1]!=\"peter\"):\n",
    "                    counter+=1\n",
    "        if counter>=number:\n",
    "            result.append(name)\n",
    "    return result\n",
    "        \n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS=[\"ps\",\"socialista\"]\n",
    "PSD=[\"psd\", \"social democrata\",\"sociais democratas\"]\n",
    "BE=[\"be\",\" bloco esquerda\", \"bloco de esquerda\",\"bloquista\"]\n",
    "CDS=[\"cds\",\"cds-pp \",\"cds-partido popular\"]\n",
    "PCP=[\"pcp\", \"cdu\", \" partido comunista \", \"comunistas\",\"partido comunista português\"]\n",
    "PEV=[\"pev\",\"partido ecologista 'os verdes'\"]\n",
    "PAN=[\"pan\", \" partido das dessoas, dos animais e da natureza\"]\n",
    "\n",
    "parties=[PS,PSD,BE,CDS,PCP,PEV,PAN]\n",
    "parties_name=[\"PS\",\"PSD\",\"BE\",\"CDS\",\"PCP\",\"PEV\",\"PAN\"]\n",
    "\n",
    "mixed_parties=dict(zip(parties_name,parties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eea2aff76af4f778eb1e02af19aee4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/15898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_media_parties_aux=data_media.body_tokens.swifter.apply(lambda x:exact_values_per_instances(x,mixed_parties,parties_name,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media_parties_aux2=update_database(data_media_parties_aux,parties_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_media_parties_aux2)==len(data_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in parties_name:\n",
    "    data_media.loc[:,party]=data_media_parties_aux2.loc[:,party]\n",
    "data_media.loc[:,\"total_parties\"]=data_media.loc[:,parties_name].sum(axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.9 - New feature: no_class_topic and no_class_party\n",
    "\n",
    "Several analyses in the remaining documents require the identification of observations that are associated with no party or topic, so these 2 new features were created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several analyses in the remaining documents require the identification of observations that are associated with no party or topic, so these 2 new features were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_class=[]\n",
    "for index_,val in enumerate(data_media.index):\n",
    "        if data_media.loc[:,topics_name].sum(axis=1).iloc[index_]==0:\n",
    "            no_class.append(1)\n",
    "        else:\n",
    "            no_class.append(0)\n",
    "            \n",
    "data_media[\"no_class_topics\"]=no_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_class=[]\n",
    "for index_,val in enumerate(data_media.index):\n",
    "        if data_media.loc[:,parties_name].sum(axis=1).iloc[index_]==0:\n",
    "            no_class.append(1)\n",
    "        else:\n",
    "            no_class.append(0)\n",
    "            \n",
    "data_media[\"no_class_parties\"]=no_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.10 - Filter for PT IJ or SDD related observations\n",
    "\n",
    "Considering that all the analyses focus solely in observations related with:\n",
    "\n",
    "1. IJ or SDD\n",
    "\n",
    "2. With PT observations\n",
    "\n",
    "The final dataset was filtered considering these 2 restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data_media_SDDJI=data_media[(data_media.SDD|data_media.JI)&(data_media.PT_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.11 - Download to pickle document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data_media_SDDJI.to_pickle(\"media_data_SDDJI.pkl\")\n",
    "\n",
    "data_media.to_pickle(\"media_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.12 - Final Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Time|title|lead|body|link|year|month|trimester|PT_data|titleSDD|titleJI|leadSDD|leadJI|bodySDD|bodyJI|SDD|JI|environment|debt|education|health|social_security|others|politics|total_topics|body_tokens|PS|PSD|BE|CDS|PCP|PEV|PAN|total_parties|no_class_topics|no_class_parties|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|Date of publication of newspaper article|Title of the newspaper article|Resume (lead) of the newspaper articles|Main text (body) of the newspaper article|Web link to access the newspaper article|Year of publication|Month of publication|Trimester of publication|Observation written in Portuguese from Portugal (Y/N)|Title classified as SDD related (Y/N)|Title classified as JI related (Y/N)|Lead classified as SDD related (Y/N)|Lead classified as JI related (Y/N)|Body classified as SDD related (Y/N)|Body classified as JI related (Y/N)|Title, or Lead, or Body classified as SDD related (Y/N)|Title, or Lead, or Body classified as JI related (Y/N)|Body classified as environment related (Y/N)|Body classified as debt related (Y/N)|Body classified as education related (Y/N)|Body classified as health related (Y/N)|Body classified as social security related (Y/N)|Body classified as related other topics (Y/N)|Body classified as politics related (Y/N)|Number of topics classification in the body text|All identified tokens in the body|Body classified as PS related (Y/N)|Body classified as PSD related (Y/N)|Body classified as BE related (Y/N)|Body classified as CDS related (Y/N)|Body classified as PCP related (Y/N)|Body classified as PEV related (Y/N)|Body classified as PAN related (Y/N)|Number of parties classifications in the body text|Body classified as not related with any topic (Y/N, 1 as not related)|Body classified as not related with any party (Y/N, 1 as not related)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Parliament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section focuses in all the data preparation methods applied only in the parliament dataset considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Data import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 - Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data=pd.read_pickle('classification_no_ins_1510.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 - Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|person_id|gender|party|date|sustentabilidade|JI|ambiente|sáude|dívida|educação|SS|segurança|empresas|agricultura|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|Politicians id|Politician's gender (M/F)|Politician's political party|Speech date|Speech classified as SDD related (Y/N)|Speech classified as JI related (Y/N)|Speech classified as environment related (Y/N)|Speech classified as health related (Y/N)|Speech classified as debt related (Y/N)|Speech classified as education related (Y/N)|Speech classified as social security related (Y/N)|Speech classified as security (one of the topic \"others\") related (Y/N)|Speech classified as business (one of the topic \"others\") related (Y/N)|Speech classified as agriculture (one of the topic \"others\") related (Y/N)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112947 entries, 4177 to 117123\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   person__id        112947 non-null  object        \n",
      " 1   gender            112947 non-null  object        \n",
      " 2   party             112947 non-null  object        \n",
      " 3   date              112947 non-null  datetime64[ns]\n",
      " 4   sustentabilidade  112947 non-null  int32         \n",
      " 5   JI                112947 non-null  int32         \n",
      " 6   ambiente          112947 non-null  int32         \n",
      " 7   saúde             112947 non-null  int32         \n",
      " 8   dívida            112947 non-null  int32         \n",
      " 9   educação          112947 non-null  int32         \n",
      " 10  SS                112947 non-null  int32         \n",
      " 11  segurança         112947 non-null  int32         \n",
      " 12  empresas          112947 non-null  int32         \n",
      " 13  agricultura       112947 non-null  int32         \n",
      "dtypes: datetime64[ns](1), int32(10), object(3)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "original_parliament_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - Filling missing values for politician-party association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although previously no null observations where identified, after a serious of analyses several observations it was observed that **some observations were filled with blank**. Although **the value does not confer any extract information it is not recognized as a null observation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False person__id\n",
      "False gender\n",
      "True party\n",
      "False date\n",
      "False sustentabilidade\n",
      "False JI\n",
      "False ambiente\n",
      "False saúde\n",
      "False dívida\n",
      "False educação\n",
      "False SS\n",
      "False segurança\n",
      "False empresas\n",
      "False agricultura\n"
     ]
    }
   ],
   "source": [
    "for column in original_parliament_data.columns:\n",
    "    print('' in original_parliament_data.loc[:,column].value_counts().index,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, a party identification process was developed to fill the observations that have no party, as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same person is sometimes associated with one specific party but other times it is associated with no party. So, **it was assumed that the same person always belonged to the party**, being possible to fill some blank observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700      UGVyc29uTm9kZTo0Mzc=\n",
       "4701      UGVyc29uTm9kZTo0Mzc=\n",
       "4702      UGVyc29uTm9kZTo0Mzc=\n",
       "4703      UGVyc29uTm9kZTo0Mzc=\n",
       "4704      UGVyc29uTm9kZTo0Mzc=\n",
       "                  ...         \n",
       "116944    UGVyc29uTm9kZTozOTM=\n",
       "116945    UGVyc29uTm9kZTozOTM=\n",
       "116946    UGVyc29uTm9kZTozOTM=\n",
       "117103    UGVyc29uTm9kZTozOTU=\n",
       "117104    UGVyc29uTm9kZTozOTU=\n",
       "Name: person__id, Length: 5631, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_withno_party=original_parliament_data[original_parliament_data.party==''].person__id\n",
    "ids_withno_party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the observations with no politicia-party association, **the most recent one was considered was considered the most reliable one**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5631"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior=original_parliament_data.party.value_counts()\n",
    "prior.loc[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "C:\\Users\\franco joao\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "for i,value in enumerate(ids_withno_party.index):\n",
    "    subset_set_parliament=original_parliament_data.loc[original_parliament_data.person__id==ids_withno_party.loc[value]]\n",
    "    list_parties=list(subset_set_parliament.party.drop_duplicates().values)\n",
    "    if \"\" in list_parties: \n",
    "        list_parties.remove('')\n",
    "        if len(list_parties)==1:\n",
    "            aux_value=list_parties[0]\n",
    "            original_parliament_data.update(original_parliament_data.loc[original_parliament_data.person__id==ids_withno_party.iloc[i]].party.replace(\"\",aux_value))\n",
    "        elif len(list_parties)>1:\n",
    "            aux1_date=subset_set_parliament.loc[subset_set_parliament.index==value].date.loc[value]\n",
    "            try:\n",
    "                # the try method needs to be included as the blank might appear before any mention to this politician in specific\n",
    "                aux_value=subset_set_parliament[(subset_set_parliament.date<=aux1_date)\n",
    "                                                &(subset_set_parliament.party!=\"\")].sort_values(by=\"date\").iloc[-1].party\n",
    "            except IndexError:\n",
    "                pass\n",
    "            original_parliament_data.loc[(original_parliament_data.person__id==ids_withno_party.iloc[i])\n",
    "                                        &(original_parliament_data.date<=aux1_date)].party.replace(\"\",aux_value,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5631, 3041)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross check to see that the replace worked\n",
    "prior.loc[\"\"],original_parliament_data.party.value_counts().loc[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UGVyc29uTm9kZTozMzM2', 'UGVyc29uTm9kZTozNDU3', 'UGVyc29uTm9kZTozMzAw',\n",
       "       'UGVyc29uTm9kZTozMzQz', 'UGVyc29uTm9kZTozMjQ0', 'UGVyc29uTm9kZTozMzQy',\n",
       "       'UGVyc29uTm9kZTozMTcz', 'UGVyc29uTm9kZTozMzMx', 'UGVyc29uTm9kZTozMjIz',\n",
       "       'UGVyc29uTm9kZTozMTk0',\n",
       "       ...\n",
       "       'UGVyc29uTm9kZTozNDU1', 'UGVyc29uTm9kZTozMjMx', 'UGVyc29uTm9kZTozNDY5',\n",
       "       'UGVyc29uTm9kZTozNjEx', 'UGVyc29uTm9kZTozMTMy', 'UGVyc29uTm9kZTozNTgx',\n",
       "       'UGVyc29uTm9kZTozMTUz', 'UGVyc29uTm9kZTozNjk2', 'UGVyc29uTm9kZTozMDc4',\n",
       "       'UGVyc29uTm9kZTozNjA3'],\n",
       "      dtype='object', length=396)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_CC=original_parliament_data.loc[original_parliament_data.party==\"\"].person__id.value_counts().index\n",
    "aux_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross check to see that all the observations that have a blank are referred to cases where that specific\n",
    "#person__id was never associated with a specific political party\n",
    "for value in aux_CC[:5]:\n",
    "    aux=original_parliament_data.loc[original_parliament_data.person__id==value].party.value_counts()\n",
    "    if (\"\" in aux.index)and(len(aux.index==1)):\n",
    "        continue\n",
    "    else:\n",
    "        print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 - Creating binary variables for party classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the maximum number of blanks spaces referred to the party politician association, we created dummy variables for eah party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties_1hot=pd.get_dummies(original_parliament_data.party)\n",
    "\n",
    "original_parliament_data=pd.merge(original_parliament_data.reset_index(),parties_1hot.reset_index(),on=\"index\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross check to see if the indexes are the same in both dataframes\n",
    "sum(original_parliament_data.index==parties_1hot.index)/len(original_parliament_data.index==parties_1hot.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 - Aggregation of parties, focusing on old parties and on left vs. right-wing division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other parties being mentioned as the data from newspaper articles starts only in 2007 and the parliament data starts in 1976. Since than many parties party coalitions have been made. Therefore, these extraordinary cases are:\n",
    "\n",
    "    - ID -Intervenção Democrática (Democratic interventation) -left wing\n",
    "    - MDPCDE -Movimento Democrático Português/Comissão Democrática Eleitoral (Portuguese Democratic Movement  / Democratic Electoral Comission) - left wing\n",
    "    - PPM -Partido Popular Monárquico (Monarchic Popular Party) - right wing\n",
    "    - PRD -Partido Renovador Democrático (Democratic Renewal Party) - right wing\n",
    "    - PSN -Partido da Solidariedade Nacional (National Solidarity Party) - left wing\n",
    "    - UDP -União Democrática Popular (Popular Democratic Union) - left wing\n",
    "    - UEDS -União da Esquerda para a Democracia Socialista (Union of the Left to Socialist Democracy) - left wing\n",
    "    \n",
    "    - ADD -no information found\n",
    "    - DR -no information found\n",
    "    \n",
    "    - PPD and PPD/PSD prior PSD\n",
    "    \n",
    "    - CDU -coalition between PCP and PEV - left wing\n",
    "    - FRS -coalition between PS and UEDS - left wing\n",
    "    - APU -coalition between PCP, PEV and MDPCDE - left wing\n",
    "    - AD -coalition between PSD, CDS and PPM - right wing\n",
    "    \n",
    "In order to aglomerate all the parties and reduce granularity of the data, the older parties that were not overtaken by a current party or coalitions will be divided according to their political orientation: left or right-wing.\n",
    "\n",
    "The respective left and right-wing classification was based on Wikipedia's classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data.loc[:,\"left_wing\"]=original_parliament_data.loc[:,[\"ID\",\"MDPCDE\",\"PSN\",\"UDP\",\"UEDS\",\"CDU\",\"FRS\",\"APU\"]].sum(axis=1)\n",
    "original_parliament_data.loc[:,\"right_wing\"]=original_parliament_data.loc[:,[\"PPM\",\"PRD\",\"AD\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data.loc[:,\"CDS_final\"]=original_parliament_data.loc[:,[\"CDS\",\"CDS-PP\"]].sum(axis=1)\n",
    "original_parliament_data.loc[:,\"PSD_final\"]=original_parliament_data.loc[:,[\"PSD\",\"PPD\",\"PPD/PSD\"]].sum(axis=1)\n",
    "original_parliament_data.loc[:,\"other_parties\"]=original_parliament_data.loc[:,[\"ADD\",\"DR\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data[\"outros\"]=original_parliament_data.agricultura+original_parliament_data.segurança+original_parliament_data.empresas\n",
    "\n",
    "aux_outros=[]\n",
    "for value in original_parliament_data.outros:\n",
    "    if value>=1:\n",
    "        aux_outros.append(1)\n",
    "    else:\n",
    "        aux_outros.append(0)\n",
    "        \n",
    "original_parliament_data[\"outros\"]=aux_outros\n",
    "#this is not made with the parties because they do not face this issue currently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 - Year, month and trimester classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data[\"year\"]=pd.DatetimeIndex(original_parliament_data.date).year\n",
    "original_parliament_data[\"month\"]=pd.DatetimeIndex(original_parliament_data.date).month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parliament_data=trimesters(original_parliament_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 - Columns naming adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data_parliament=original_parliament_data.loc[:,['person__id', 'gender', 'party', 'date', 'sustentabilidade', 'JI',\n",
    "       'ambiente', 'saúde', 'dívida', 'educação', 'SS', 'segurança',\n",
    "       'empresas', 'agricultura', 'year', 'month','trimester','outros', '',\n",
    "       'BE', 'PAN', 'PCP','other_parties',\n",
    "                                                           \n",
    "       'PEV', 'PS', 'CDS_final', 'PSD_final', 'left_wing','right_wing']].copy()\n",
    "classified_data_parliament=classified_data_parliament.rename(columns={\"CDS_final\":\"CDS\",\"PSD_final\":\"PSD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_topics=dict(zip(['ambiente', 'dívida','educação','saúde','SS', 'outros',],topics_name_w_politics))\n",
    "\n",
    "classified_data_parliament=classified_data_parliament.rename(columns=rename_topics)\n",
    "classified_data_parliament=classified_data_parliament.rename(columns={\"segurança\":\"security\",\"empresas\":\"business\",\"agricultura\":\"agriculture\"})\n",
    "classified_data_parliament=classified_data_parliament.rename(columns={\"sustentabilidade\":\"SDD\"})\n",
    "classified_data_parliament=classified_data_parliament.rename(columns={\"\":\"no_party_classification\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 - New feature: no_class_topic\n",
    "\n",
    "Several analyses in the remaining documents require the identification of observations that are associated with no party or topic, so these 2 new features were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_class=[]\n",
    "aux=classified_data_parliament.loc[:,topics_name].sum(axis=1)\n",
    "for index_,val in enumerate(classified_data_parliament.index):\n",
    "        if aux.iloc[index_]==0:\n",
    "            no_class.append(1)\n",
    "        else:\n",
    "            no_class.append(0)\n",
    "            \n",
    "classified_data_parliament[\"no_class_topics\"]=no_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 - Filter for IJ or SDD related observations\n",
    "\n",
    "Considering that all the analyses focus solely in observations related with:\n",
    "\n",
    "1. IJ or SDD\n",
    "\n",
    "The final dataset was filtered considering this restriction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classified_data_parliament=classified_data_parliament[classified_data_parliament.loc[:,[\"JI\",\"SDD\"]].sum(axis=1)!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 - Download to pickle document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classified_data_parliament.to_pickle(\"parliament_data_SDDJI.pkl\")\n",
    "\n",
    "classified_data_parliament.to_pickle(\"parliament_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.9 - Final Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|person_id|gender|party|date|sustentabilidade|JI|environment|health|debt|education|social_security|security|business|agriculture|year|month|trimester|others|no_party_classification|BE|PAN|PCP|other_parties|PEV|PS|CDS|PSD|left_wing|right_wing|no_class_topics|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|Politicians id|Politician's gender (M/F)|Politician's political party|Speech date|Speech classified as SDD related (Y/N)|Speech classified as JI related (Y/N)|Speech classified as environment related (Y/N)|Speech classified as health related (Y/N)|Speech classified as debt related (Y/N)|Speech classified as education related (Y/N)|Speech classified as social security related (Y/N)|Speech classified as security (one of the topic \"others\") related (Y/N)|Speech classified as companie (one of the topic \"others\") related (Y/N)|Speech classified as agriculture (one of the topic \"others\") related (Y/N)|Speech's year|Speech's month|Speech's trimeter|Speech classified as related with topic \"others\" (Y/N)|Speech not classified with any topic (Y/N)|Speech's politician associated with BE (Y/N)|Speech's politician associated with PAN (Y/N)|Speech's politician associated with PCP (Y/N)|Speech's politician associated with the other parties identified (\"ADD\" or \"DR\") (Y/N)|Speech's politician associated with PEV (Y/N)|Speech's politician associated with PS (Y/N)|Speech's politician associated with CDS (Y/N)|Speech's politician associated with PSD (Y/N)|Speech's politician associated with the left wing identified parties (\"ID\",\"MDPCDE\",\"PSN\",\"UDP\",\"UEDS\",\"CDU\",\"FRS\",\"APU\") (Y/N)|Speech's politician associated with the right wing identified parties (\"PPM\",\"PRD\",\"AD\") (Y/N)|Speech classified as not related with any topic (Y/N, 1 as not related)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Social Media data (Twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 - Data upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets were extracted in 2 parts, hence the existance of 2 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data=pd.read_pickle(\"tweets_data.pkl\")\n",
    "\n",
    "tweets_data_pt=pd.read_pickle(\"tweets_data_pt.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 - Legends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nbr_retweet|user_id|url|text|usernameTweet|datetime|is_reply|is_retweet|ID|nbr_reply|nbr_favorite|medias|has_media|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|Number of retweets of observation's tweet|id of the user that published the tweet|Tweet's url text|Tweet's text|Username of the tweet's publisher|Tweet's publication date|Tweet classification as a reply tweet (Y/N)|Tweet classification as a retweet tweet (Y/N)|Tweet's id|Number of reply of the tweet|Number of users that considered the tweet as a favourite tweet|Link mentioned in the tweet|Tweet with an associated link(Y/N)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Data Treatment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 - Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.concat([tweets_data,tweets_data_pt]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the prior merger, and to ensure proper indexes, the index column was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=tweets.drop(\"index\",axis=1)\n",
    "tweets.loc[:,\"index\"]=range(len(tweets))\n",
    "tweets=tweets.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 - Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tweets.ID.value_counts().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each tweet is associated a single ID, we can ensure that there are no duplicates in the datasets used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3- Filling missing values and ensure has_media feature coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69857 entries, 0 to 69856\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   nbr_retweet    69857 non-null  int64 \n",
      " 1   user_id        69857 non-null  object\n",
      " 2   url            69857 non-null  object\n",
      " 3   text           69857 non-null  object\n",
      " 4   usernameTweet  69857 non-null  object\n",
      " 5   datetime       69857 non-null  object\n",
      " 6   is_reply       69857 non-null  bool  \n",
      " 7   is_retweet     69857 non-null  bool  \n",
      " 8   ID             69857 non-null  object\n",
      " 9   nbr_reply      69857 non-null  int64 \n",
      " 10  nbr_favorite   69857 non-null  int64 \n",
      " 11  medias         1770 non-null   object\n",
      " 12  has_media      1770 non-null   object\n",
      "dtypes: bool(2), int64(3), object(8)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.medias.fillna(\"Nan\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.has_media.fillna(False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to confirm that all columns with True in has_media feature in fact have a link, and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nan                        170\n",
       "https://t.co/b6MxA0ntNH      7\n",
       "http://t.co/DqKZLGj4         6\n",
       "https://t.co/3HbqZ5E9jb      5\n",
       "https://t.co/YcJuQ2FWop      3\n",
       "                          ... \n",
       "https://t.co/QOTMJkwa1c      1\n",
       "https://t.co/kdPeLmm8u9      1\n",
       "http://t.co/mhcSfPwqnd       1\n",
       "https://t.co/0FQtwGu0bU      1\n",
       "https://t.co/0iHTBqq2ZQ      1\n",
       "Name: medias, Length: 1562, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets.has_media==True].medias.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_col=[]\n",
    "for ids,value in enumerate(tweets.index):\n",
    "    if (tweets.has_media.iloc[ids]==True)&(tweets.medias.iloc[ids]==\"Nan\"):\n",
    "        aux_col.append(False)\n",
    "    else:\n",
    "        aux_col.append(tweets.has_media.iloc[ids])\n",
    "        \n",
    "tweets[\"has_media\"]=aux_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "len(tweets[(tweets.has_media==True)&(tweets.medias==\"Nan\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69857 entries, 0 to 69856\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   nbr_retweet    69857 non-null  int64 \n",
      " 1   user_id        69857 non-null  object\n",
      " 2   url            69857 non-null  object\n",
      " 3   text           69857 non-null  object\n",
      " 4   usernameTweet  69857 non-null  object\n",
      " 5   datetime       69857 non-null  object\n",
      " 6   is_reply       69857 non-null  bool  \n",
      " 7   is_retweet     69857 non-null  bool  \n",
      " 8   ID             69857 non-null  object\n",
      " 9   nbr_reply      69857 non-null  int64 \n",
      " 10  nbr_favorite   69857 non-null  int64 \n",
      " 11  medias         69857 non-null  object\n",
      " 12  has_media      69857 non-null  bool  \n",
      "dtypes: bool(3), int64(3), object(7)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 - Inserting date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"year\"]=pd.DatetimeIndex(tweets.datetime).year\n",
    "tweets[\"month\"]=pd.DatetimeIndex(tweets.datetime).month\n",
    "tweets=trimesters(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 - Converting text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"]=[text.lower() for text in tweets.loc[:,\"text\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 - SDD or JI classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"SDD\"]=tweets.text.str.contains(\"sustentável|insustentável|sustentabilidade|insustentabilidade|sustentar\")\n",
    "tweets[\"JI\"]=tweets.text.str.contains(\"interger|gerações vindouras|gerações futuras|geração futura|próxima geração|justiça entre gerações|geração vindoura|geração seguinte|gerações presentes|entre gerações|próximas gerações|gerações mais jovens| novas gerações| gerações distintas| próximas gerações\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 - SDD or JI related topics classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(lists):\n",
    "    return [i for minilist in lists for i in minilist ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "business=[\"organizações\",\"trabalho\",\"empreendedor\",\"investimento\"]\n",
    "\n",
    "society=[\"cidade\",\"social\",\"popul\",\"transporte\",\"consumidores\"]\n",
    "\n",
    "topics_twitter=unpack([[business,society],topics])\n",
    "\n",
    "topics_name_w_politics_twitter=unpack([[\"business\",\"society\"],topics_name_w_politics])\n",
    "topics_name_w_politics_twitter_exp_politics=topics_name_w_politics_twitter[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a569d3799fd74971a9823948438b22d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/69857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78821e023d0547ee8bd85d6bf363c7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/69857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_tokens=tweets.text.swifter.apply(word_tokenize)\n",
    "\n",
    "tweets_topics=tweets.text.swifter.apply(lambda x:values_per_instances(x,topics_twitter,topics_name_w_politics_twitter,1))\n",
    "\n",
    "topics_count=update_database(tweets_topics,topics_name_w_politics_twitter)\n",
    "\n",
    "tweets_final=pd.merge(tweets.reset_index(),topics_count.reset_index(),on=\"index\").set_index(\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans_no_class=tweets_final.loc[:,topics_name_w_politics_twitter_exp_politics].sum(axis=1)==0\n",
    "\n",
    "no_class=[]\n",
    "\n",
    "for i in booleans_no_class:\n",
    "    if i:\n",
    "        no_class.append(1)\n",
    "    else:\n",
    "        no_class.append(0)\n",
    "        \n",
    "tweets_final.loc[:,\"no_class_topic\"]=no_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8 - Filter for IJ or SDD related observations\n",
    "\n",
    "Considering that all the analyses focus solely in observations related with:\n",
    "\n",
    "1. IJ or SDD\n",
    "\n",
    "The final dataset was filtered considering this restriction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final_SDDJI=tweets_final[tweets_final.loc[:,[\"JI\",\"SDD\"]].sum(axis=1)!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.9 - Download to pickle document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final.to_pickle(\"tweets_data_final.pkl\")\n",
    "\n",
    "tweets_final_SDDJI.to_pickle(\"tweets_data_final_SDDJI.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.10 - Final Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|nbr_retweet|user_id|url|text|usernameTweet|datetime|is_reply|is_retweet|ID|nbr_reply|nbr_favorite|medias|has_media|year|month|trimester|SDD|JI|business|society|environment|debt|education|health|social security|others|politics|no_class_topic|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|Number of retweets of observation's tweet|id of the user that published the tweet|Tweet's url text|Tweet's text|Username of the tweet's publisher|Tweet's publication date|Tweet classification as a reply tweet (Y/N)|Tweet classification as a retweet tweet (Y/N)|Tweet's id|Number of reply of the tweet|Number of users that considered the tweet as a favourite tweet|Link mentioned in the tweet|Tweet with an associated link(Y/N)|Tweet's publication year|Tweet's publication month|Tweet's publication trimester|Tweet classified as SDD related (Y/N)|Tweet classified as JI related (Y/N)|Tweet classified as business related (Y/N)|Tweet classified as society related (Y/N)|Tweet classified as environment related (Y/N)|Tweet classified as debt related (Y/N)|Tweet classified as education related (Y/N)|Tweet classified as health related (Y/N)|Tweet classified as social security related (Y/N)|Tweet classified as related with the topic others (Y/N)|Tweet classified as politics related (Y/N)|Tweet classified as not related with any topic (Y/N, 1 as not related)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
